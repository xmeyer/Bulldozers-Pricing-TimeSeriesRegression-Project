{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the Sale Price of Bulldozers using Machine Learning\n",
    "\n",
    "In this notebook, we're going to go through an example machine learning project with the goals of predicting the sale price of bulldozers.\n",
    "\n",
    "## 1. Problem Definition\n",
    "\n",
    "> How well can we predict the future sale price of a bulldozer, given its characteristics and previous examples of how much similar bulldozers have been sold for?\n",
    "\n",
    "## 2. Data\n",
    "\n",
    "The data is downloaded from the Kaggle Bluebook for Bulldozers competition:\n",
    "\n",
    "There are 3 main datasets:\n",
    "\n",
    "* Train.csv is the training set, which contains data through the end of 2011.\n",
    "* Valid.csv is the validation set, which contains data from January 1, 2012 - April 30, 2012 You make predictions on this set throughout the majority of the competition. Your score on this set is used to create the public leaderboard.\n",
    "* Test.csv is the test set, which won't be released until the last week of the competition. It contains data from May 1, 2012 - November 2012. Your score on the test set determines your final rank for the competition.\n",
    "\n",
    "## 3. Evaluation\n",
    "\n",
    "The evaluation metric for this competition is the RMSLE (root mean squared log error) between the actual and predicted auction prices. \n",
    "\n",
    "For more on the evalauation of this project, check:\n",
    "https://www.kaggle.com/c/bluebook-for-bulldozers/overview/evaluation\n",
    "\n",
    "**Note:** The goal for the most regression evaluation metrics is to minimize the error. For example, our goal for this project will be to build a machine learning model, which minimzes RMSLE.\n",
    "\n",
    "## 4. Features\n",
    "\n",
    "Features are different parts of the data. During this step, you'll want to start finding out what you can about the data.\n",
    "\n",
    "One of the most common ways to do this, is to create a data dictionary.\n",
    "\n",
    "For this dataset, Kaggle provide a data dictionary which contains information about what each attribute of the dataset means. You can download this file directly from the Kaggle competition page (account required) or view it on Google Sheets.\n",
    "\n",
    "With all of this being known, let's get started!\n",
    "\n",
    "First, we'll import the dataset and start exploring. Since we know the evaluation metric we're trying to minimise, our first goal will be building a baseline model and seeing how it stacks up against the competition.\n",
    "\n",
    "### Importing the data and preparing it for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the training and valiadation sets\n",
    "df = pd.read_csv('C:/Users/xavie/Downloads/bluebook-for-bulldozers/bluebook-for-bulldozers/TrainAndValid.csv',\n",
    "                 low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 412698 entries, 0 to 412697\n",
      "Data columns (total 59 columns):\n",
      " #   Column                              Non-Null Count   Dtype  \n",
      "---  ------                              --------------   -----  \n",
      " 0   SalesID                             412698 non-null  int64  \n",
      " 1   SalePrice                           412698 non-null  float64\n",
      " 2   MachineID                           412698 non-null  int64  \n",
      " 3   ModelID                             412698 non-null  int64  \n",
      " 4   datasource                          412698 non-null  int64  \n",
      " 5   auctioneerID                        412698 non-null  float64\n",
      " 6   YearMade                            412698 non-null  int64  \n",
      " 7   MachineHoursCurrentMeter            412698 non-null  float64\n",
      " 8   UsageBand                           73670 non-null   object \n",
      " 9   fiModelDesc                         412698 non-null  object \n",
      " 10  fiBaseModel                         412698 non-null  object \n",
      " 11  fiSecondaryDesc                     271971 non-null  object \n",
      " 12  fiModelSeries                       58667 non-null   object \n",
      " 13  fiModelDescriptor                   74816 non-null   object \n",
      " 14  ProductSize                         196093 non-null  object \n",
      " 15  fiProductClassDesc                  412698 non-null  object \n",
      " 16  state                               412698 non-null  object \n",
      " 17  ProductGroup                        412698 non-null  object \n",
      " 18  ProductGroupDesc                    412698 non-null  object \n",
      " 19  Drive_System                        107087 non-null  object \n",
      " 20  Enclosure                           412364 non-null  object \n",
      " 21  Forks                               197715 non-null  object \n",
      " 22  Pad_Type                            81096 non-null   object \n",
      " 23  Ride_Control                        152728 non-null  object \n",
      " 24  Stick                               81096 non-null   object \n",
      " 25  Transmission                        188007 non-null  object \n",
      " 26  Turbocharged                        81096 non-null   object \n",
      " 27  Blade_Extension                     25983 non-null   object \n",
      " 28  Blade_Width                         25983 non-null   object \n",
      " 29  Enclosure_Type                      25983 non-null   object \n",
      " 30  Engine_Horsepower                   25983 non-null   object \n",
      " 31  Hydraulics                          330133 non-null  object \n",
      " 32  Pushblock                           25983 non-null   object \n",
      " 33  Ripper                              106945 non-null  object \n",
      " 34  Scarifier                           25994 non-null   object \n",
      " 35  Tip_Control                         25983 non-null   object \n",
      " 36  Tire_Size                           97638 non-null   object \n",
      " 37  Coupler                             220679 non-null  object \n",
      " 38  Coupler_System                      44974 non-null   object \n",
      " 39  Grouser_Tracks                      44875 non-null   object \n",
      " 40  Hydraulics_Flow                     44875 non-null   object \n",
      " 41  Track_Type                          102193 non-null  object \n",
      " 42  Undercarriage_Pad_Width             102916 non-null  object \n",
      " 43  Stick_Length                        102261 non-null  object \n",
      " 44  Thumb                               102332 non-null  object \n",
      " 45  Pattern_Changer                     102261 non-null  object \n",
      " 46  Grouser_Type                        102193 non-null  object \n",
      " 47  Backhoe_Mounting                    80712 non-null   object \n",
      " 48  Blade_Type                          81875 non-null   object \n",
      " 49  Travel_Controls                     81877 non-null   object \n",
      " 50  Differential_Type                   71564 non-null   object \n",
      " 51  Steering_Controls                   71522 non-null   object \n",
      " 52  saleYear                            412698 non-null  int64  \n",
      " 53  saleMonth                           412698 non-null  int64  \n",
      " 54  saleDay                             412698 non-null  int64  \n",
      " 55  saleDayOfWeek                       412698 non-null  int64  \n",
      " 56  saleDayOfYear                       412698 non-null  int64  \n",
      " 57  auctioneerIDis_missing              412698 non-null  bool   \n",
      " 58  MachineHoursCurrentMeteris_missing  412698 non-null  bool   \n",
      "dtypes: bool(2), float64(3), int64(10), object(44)\n",
      "memory usage: 180.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalesID                                    0\n",
       "SalePrice                                  0\n",
       "MachineID                                  0\n",
       "ModelID                                    0\n",
       "datasource                                 0\n",
       "auctioneerID                               0\n",
       "YearMade                                   0\n",
       "MachineHoursCurrentMeter                   0\n",
       "UsageBand                             339028\n",
       "fiModelDesc                                0\n",
       "fiBaseModel                                0\n",
       "fiSecondaryDesc                       140727\n",
       "fiModelSeries                         354031\n",
       "fiModelDescriptor                     337882\n",
       "ProductSize                           216605\n",
       "fiProductClassDesc                         0\n",
       "state                                      0\n",
       "ProductGroup                               0\n",
       "ProductGroupDesc                           0\n",
       "Drive_System                          305611\n",
       "Enclosure                                334\n",
       "Forks                                 214983\n",
       "Pad_Type                              331602\n",
       "Ride_Control                          259970\n",
       "Stick                                 331602\n",
       "Transmission                          224691\n",
       "Turbocharged                          331602\n",
       "Blade_Extension                       386715\n",
       "Blade_Width                           386715\n",
       "Enclosure_Type                        386715\n",
       "Engine_Horsepower                     386715\n",
       "Hydraulics                             82565\n",
       "Pushblock                             386715\n",
       "Ripper                                305753\n",
       "Scarifier                             386704\n",
       "Tip_Control                           386715\n",
       "Tire_Size                             315060\n",
       "Coupler                               192019\n",
       "Coupler_System                        367724\n",
       "Grouser_Tracks                        367823\n",
       "Hydraulics_Flow                       367823\n",
       "Track_Type                            310505\n",
       "Undercarriage_Pad_Width               309782\n",
       "Stick_Length                          310437\n",
       "Thumb                                 310366\n",
       "Pattern_Changer                       310437\n",
       "Grouser_Type                          310505\n",
       "Backhoe_Mounting                      331986\n",
       "Blade_Type                            330823\n",
       "Travel_Controls                       330821\n",
       "Differential_Type                     341134\n",
       "Steering_Controls                     341176\n",
       "saleYear                                   0\n",
       "saleMonth                                  0\n",
       "saleDay                                    0\n",
       "saleDayOfWeek                              0\n",
       "saleDayOfYear                              0\n",
       "auctioneerIDis_missing                     0\n",
       "MachineHoursCurrentMeteris_missing         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'saledate'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'saledate'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-167-6878ff4d8e63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'saledate'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SalePrice'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m \u001b[1;31m# troubles b/c of saledate data type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'saledate'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df['saledate'][:1000], df['SalePrice'][:1000]); # troubles b/c of saledate data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.SalePrice.plot.hist(); # great display of price and sell of bulldozers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.saledate[:1000] # dtype object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing dates\n",
    "\n",
    "When we work with time series data,  we want to enrich the time and date component as much as possible.\n",
    "\n",
    "We can do that by telling pandas which of our columns has dates in it, using the `parse dates` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data again, but this time parse dates\n",
    "df = pd.read_csv('C:/Users/xavie/Downloads/bluebook-for-bulldozers/bluebook-for-bulldozers/TrainAndValid.csv',\n",
    "                 low_memory = False,\n",
    "                 parse_dates = ['saledate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.saledate.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.saledate[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(df['saledate'][:1000], df['SalePrice'][:1000]); # can now research the reason behind the markets behavior for further context of data, if you'd like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head().T # T is to transpose, so that all the columns can be viewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.saledate.head(20) # dates are out of order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort DataFrame by saledate\n",
    "\n",
    "When working with time series data, it's a good idea to sort it by date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort DataFrame in date order\n",
    "df.sort_values(by = ['saledate'], inplace = True, ascending = True)\n",
    "df.saledate.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a copy of the original DataFrame\n",
    "\n",
    "We make a copy of the original DataFrame, so when we manipulate the copy, we've still got our original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy\n",
    "df_tmp = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.head(20).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add datetime parameters for `saledate` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp['saleYear'] = df_tmp.saledate.dt.year\n",
    "df_tmp['saleMonth'] = df_tmp.saledate.dt.month\n",
    "df_tmp['saleDay'] = df_tmp.saledate.dt.day\n",
    "df_tmp['saleDayOfWeek'] = df_tmp.saledate.dt.dayofweek\n",
    "df_tmp['saleDayOfYear'] = df_tmp.saledate.dt.dayofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we've enriched our DataFrame with date time features, we can remove saledate\n",
    "df_tmp.drop('saledate', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the values of different columns\n",
    "df_tmp.state.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelling\n",
    "\n",
    "We've done enough EDA. We could always do more, but let's start to do some model-driven EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build a machine learning model\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_jobs = -1, \n",
    "                              random_state = 42) # same as np.random.seed(42)\n",
    "model.fit(df_tmp.drop('SalePrice', axis = 1, ), df_tmp['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ValueError: could not convert string to float: 'Low'**\n",
    "\n",
    "Need to fix the data types of the different columns, and handle the missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing categories and different datatypes\n",
    "df_tmp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df_tmp.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert string to category\n",
    "\n",
    "One way we can turn all of our data into numbers is by converting them in categories.\n",
    "\n",
    "We can check the different data types compatible with pandas here:\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/general_utility_functions.html#data-types-related-functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.api.types.is_string_dtype(df_tmp['UsageBand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the columns which contains strings\n",
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_string_dtype(content):\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you're wondering what df.items() does, here's an example\n",
    "random_dict = {'key1': 'hello',\n",
    "               'key2': 'world!'}\n",
    "\n",
    "for key, value in random_dict.items():\n",
    "    print(f'This is a key: {key}')\n",
    "    print(f'This is a value: {value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will turn all the string values into category values\n",
    "for label, content in df_tmp.items():\n",
    "    if  pd.api.types.is_string_dtype(content):\n",
    "        df_tmp[label] = content.astype('category').cat.as_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.state.cat.categories # still looks like strings, but pandas treats them as numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.state.cat.codes # each state (all category columns) is a number now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to pandas Categories, we now have a way to access all of our data in the form of numbers.\n",
    "\n",
    "But we still have a bunch of missing data.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing data\n",
    "df_tmp.isna().sum()/ len(df_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed data (Export current tmp DataFrame)\n",
    "df_tmp.to_csv('C:/Users/xavie/Downloads/bluebook-for-bulldozers/bluebook-for-bulldozers/TrainAndValid.csv',\n",
    "              index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import preprocessed data\n",
    "df_tmp = pd.read_csv(\"C:/Users/xavie/Downloads/bluebook-for-bulldozers/bluebook-for-bulldozers/TrainAndValid.csv\",\n",
    "                     low_memory=False)\n",
    "df_tmp.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill missing values\n",
    "\n",
    "From our experience with machine learning models. We know two things:\n",
    "1. All of our data has to be numerical\n",
    "2. There can't be any missing values\n",
    "\n",
    "And as we've seen using df_tmp.isna().sum() our data still has plenty of missing values.\n",
    "\n",
    "Let's fill them.\n",
    "\n",
    "### Fill numerical missing values first\n",
    "\n",
    "We're going to fill any column with missing values with the median of that column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.ModelID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for which numeric columns have null values\n",
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill numeric rows with the median\n",
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            # Add a binary column to tell us if the data was missing or not\n",
    "            df_tmp[label + '_is_missing'] = pd.isnull(content) # column acknowledges a row had missing data, just in case, after the row is filled, we find out later that it was important for the column to be missing data\n",
    "            # Fill missing numeric values with median\n",
    "            df_tmp[label] = content.fillna(content.median()) # median is more robust than mean (mean is very sensitive to outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate how median is more robust than mean\n",
    "# 1,000 people with 100 dollars on them\n",
    "hundreds = np.full((1000,), 100) \n",
    "# Bill Gates walks in with a billion dollars\n",
    "hundreds_billion = np.append(hundreds, 1000000000)\n",
    "np.mean(hundreds), np.mean(hundreds_billion), np.median(hundreds), np.median(hundreds_billion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there's any null numeric values\n",
    "for label, content in df_tmp.items():\n",
    "    if pd.api.types.is_numeric_dtype(content):\n",
    "        if pd.isnull(content).sum():\n",
    "            print(label) # prints nothing because it is filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see how many examples were missing\n",
    "df_tmp.auctioneerID_is_missing.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling and turning categorical variables into numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for columns which aren't numeric\n",
    "for label, content in df_tmp.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Categorical(df_tmp['state']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn categroical variables into numbers and fill missing\n",
    "for label, content in df_tmp.items():\n",
    "    if not pd.api.types.is_numeric_dtype(content):\n",
    "        # Add binary column to indicate whether sample had missing value\n",
    "        df_tmp[label + '_is_missing'] = pd.isnull(content)\n",
    "        # Turn categories into numbers and add +1\n",
    "        df_tmp[label] = pd.Categorical(content).codes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas assigns missing values a -1, so do +1 to make them 0\n",
    "pd.Categorical(df_tmp['state']).codes + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of why we do +1\n",
    "pd.Categorical(df_tmp['UsageBand']).codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that all of data is numeric, as well as our dataframe has no missing values, we should be able to build a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# One of many Jupyter magic functions - calculates time cell takes to run\n",
    "\n",
    "# Instantiate model\n",
    "model = RandomForestRegressor(n_jobs = -1,\n",
    "                               random_state = 42)\n",
    "\n",
    "# Fit the model (dataframe is train and valid data)\n",
    "model.fit(df_tmp.drop('SalePrice', axis = 1), df_tmp['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score the model\n",
    "model.score(df_tmp.drop('SalePrice', axis = 1), df_tmp['SalePrice'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Why isn't this metric reliable?\n",
    "\n",
    "Remember: \n",
    "\n",
    "* Train.csv is the training set, which contains data through the end of 2011.\n",
    "* Valid.csv is the validation set, which contains data from January 1, 2012 - April 30, 2012 You make predictions on this set throughout the majority of the competition. Your score on this set is used to create the public leaderboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into train/ validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.saleYear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tmp.saleYear.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "df_val = df_tmp[df_tmp.saleYear == 2012]\n",
    "df_train = df_tmp[df_tmp.saleYear != 2012]\n",
    "\n",
    "len(df_val), len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dat into X & y\n",
    "X_train, y_train = df_train.drop('SalePrice', axis = 1), df_train.SalePrice\n",
    "X_valid, y_valid = df_val.drop('SalePrice', axis = 1), df_val.SalePrice\n",
    "\n",
    "X_train.shape, y_train.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building an evaluation function\n",
    "According to Kaggle for the Bluebook for Bulldozers competition, the evaluation function they use is root mean squared log error (RMSLE).\n",
    "\n",
    "**RMSLE** = generally you don't care as much if you're off by $10 as much as you'd care if you were off by 10%, you care more about ratios rather than differences. **MAE** (mean absolute error) is more about exact differences.\n",
    "\n",
    "It's important to understand the evaluation metric you're going for.\n",
    "\n",
    "Since Scikit-Learn doesn't have a function built-in for RMSLE, we'll create our own.\n",
    "\n",
    "We can do this by taking the square root of Scikit-Learn's mean_squared_log_error (MSLE). MSLE is the same as taking the log of mean squared error (MSE).\n",
    "\n",
    "We'll also calculate the MAE and R^2 for fun."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create evaluation function (the competition uses Root Mean Square Log Error)\n",
    "from sklearn.metrics import mean_squared_log_error, mean_absolute_error, r2_score\n",
    "\n",
    "def rmsle(y_test, y_preds):\n",
    "    '''\n",
    "    Calculate root mean squred log error between predictions and\n",
    "    true labels.\n",
    "    '''\n",
    "    return np.sqrt(mean_squared_log_error(y_test, y_preds))\n",
    "\n",
    "# Create function to evaluate model on a few different levels\n",
    "def show_scores(model):\n",
    "    train_preds = model.predict(X_train)\n",
    "    val_preds = model.predict(X_valid) # better than train preds = overfit\n",
    "    scores = {\"Training MAE\": mean_absolute_error(y_train, train_preds),\n",
    "              \"Valid MAE\": mean_absolute_error(y_valid, val_preds),\n",
    "              \"Training RMSLE\": rmsle(y_train, train_preds),\n",
    "              \"Valid RMSLE\": rmsle(y_valid, val_preds),\n",
    "              \"Training R^2\": r2_score(y_train, train_preds),\n",
    "              \"Valid R^2\": r2_score(y_valid, val_preds)}\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our model on a subset (to tune the hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes far too long for experimenting\n",
    "\n",
    "# %%time\n",
    "# model = RandomForestRegressor(n_jobs = -1,\n",
    "#                              random_state = 42)\n",
    "\n",
    "# model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change max_samples value\n",
    "model = RandomForestRegressor(n_jobs = -1,\n",
    "                              random_state = 42,\n",
    "                              max_samples = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Cutting down on the max number of samples each estimator can see improves training time\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scores(model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning eith RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Different RandomForestRegressor hyperparameters\n",
    "rf_grid = {'n_estimators': np.arange(10, 100, 10),\n",
    "           'max_depth': [None, 3, 5, 10],\n",
    "           'min_samples_split': np.arange(2, 20, 2),\n",
    "           'min_samples_leaf': np.arange(1, 20, 2),\n",
    "           'max_features': [0.5, 1, 'sqrt', 'auto'],\n",
    "           'max_samples': [10000]}\n",
    "\n",
    "# Instantiate RandomizedSearchCV model\n",
    "rs_model = RandomizedSearchCV(RandomForestRegressor(n_jobs = -1,\n",
    "                                                    random_state = 42),\n",
    "                              param_distributions = rf_grid,\n",
    "                              n_iter = 2, # to keep the cell time down\n",
    "                              cv = 5,\n",
    "                              verbose = True)\n",
    "\n",
    "# Fit the RandomizedSearchCV model\n",
    "rs_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the best model hyperparameters\n",
    "rs_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the RandomizedSearch model\n",
    "show_scores(rs_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a model with the best hyperparameters\n",
    "\n",
    "In a model I prepared earlier, I tried 100 different combinations of hyperparameters (setting n_iter to 100 in `RandomizedSearchCV)` and found the best results came from the ones you see below.\n",
    "\n",
    "**Note:** This kind of search on my computer (n_iter = 100) took ~2-hours. So it's kind of a set and come back later experiment.\n",
    "\n",
    "We'll instantiate a new model with these discovered hyperparameters and reset the max_samples back to its original value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Most ideal hyperparameters\n",
    "ideal_model = RandomForestRegressor(n_estimators=40,\n",
    "                                    min_samples_leaf=1,\n",
    "                                    min_samples_split=14,\n",
    "                                    max_features=0.5,\n",
    "                                    n_jobs=-1,\n",
    "                                    max_samples=None,\n",
    "                                    random_state=42) # random state so our results are reproducible\n",
    "\n",
    "# Fit the ideal model\n",
    "ideal_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores for ideal model (trained on all the data)\n",
    "show_scores(ideal_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores on rs_model (only trained on ~10,000 examples)\n",
    "show_scores(rs_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the test data\n",
    "df_test = pd.read_csv('C:/Users/xavie/Downloads/bluebook-for-bulldozers/bluebook-for-bulldozers/Test.csv',\n",
    "                       low_memory = False,\n",
    "                       parse_dates = ['saledate'])\n",
    "\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test dataset\n",
    "test_preds = ideal_model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.isna().sum() # Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() # values are not numeric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing the data (getting the test data set in the same format as the training dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    '''\n",
    "    Performs transformations on df, and returns transformed df.\n",
    "    '''\n",
    "    df[\"saleYear\"] = df.saledate.dt.year\n",
    "    df[\"saleMonth\"] = df.saledate.dt.month\n",
    "    df[\"saleDay\"] = df.saledate.dt.day\n",
    "    df[\"saleDayOfWeek\"] = df.saledate.dt.dayofweek\n",
    "    df[\"saleDayOfYear\"] = df.saledate.dt.dayofyear\n",
    "    \n",
    "    df.drop(\"saledate\", axis=1, inplace=True)\n",
    "    \n",
    "    # Fill the numeric rows with median\n",
    "    for label, content in df.items():\n",
    "        if pd.api.types.is_numeric_dtype(content):\n",
    "            if pd.isnull(content).sum():\n",
    "                # Add a binary column which tells us if the data was missing or not\n",
    "                df[label+\"_is_missing\"] = pd.isnull(content)\n",
    "                # Fill missing numeric values with median\n",
    "                df[label] = content.fillna(content.median())\n",
    "    \n",
    "        # Fill categorical missing data and turn categories into numbers\n",
    "        if not pd.api.types.is_numeric_dtype(content):\n",
    "            df[label+\"_is_missing\"] = pd.isnull(content)\n",
    "            # We add +1 to the category code because pandas encodes missing categories as -1\n",
    "            df[label] = pd.Categorical(content).codes+1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Where would this function break?\n",
    "\n",
    "**Hint:** What if the test data had different missing values to the training data?\n",
    "\n",
    "Now we've got a function for preprocessing data, let's preprocess the test dataset into the same format as our training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the test data\n",
    "df_test = preprocess_data(df_test)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on updated test data\n",
    "test_preds = ideal_model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can find out how the columns are different using sets\n",
    "set(X_train.columns) - set(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually adjust df_test to have auctioneerID_is_missing column\n",
    "df_test[\"auctioneerID_is_missing\"] = False\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally now our test dataframe has the same features as our training dataframe, we can make predictions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "test_preds = ideal_model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've made some predictions but they're not in the same format Kaggle is asking for. When looking at the Kaggle submission requirements, we see that if we wanted to make a submission, the data is required to be in a certain format. Namely, a DataFrame containing the SalesID and the predicted SalePrice of the bulldozer.\n",
    "\n",
    "https://www.kaggle.com/c/bluebook-for-bulldozers/overview/evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format predictions into the same format Kaggle is after\n",
    "df_preds = pd.DataFrame()\n",
    "df_preds[\"SalesID\"] = df_test[\"SalesID\"]\n",
    "df_preds[\"SalesPrice\"] = test_preds\n",
    "df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export prediction data\n",
    "df_preds.to_csv(\"data/bluebook-for-bulldozers/test_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "\n",
    "Since we've built a model which is able to make predictions. The people you share these predictions with (or yourself) might be curious of what parts of the data led to these predictions.\n",
    "\n",
    "This is where **feature importance** comes in. Feature importance seeks to figure out which different attributes of the data were most important when it comes to predicting the **target variable**.\n",
    "\n",
    "In our case, after our model learned the patterns in the data, which bulldozer sale attributes were most important for predicting its overall sale price?\n",
    "\n",
    "Beware: the default feature importances for random forests can lead to non-ideal results.\n",
    "\n",
    "To find which features were most important of a machine learning model, a good idea is to search something like \"[MODEL NAME] feature importance\".\n",
    "\n",
    "Doing this for our `RandomForestRegressor` leads us to find the `feature_importances_` attribute.\n",
    "\n",
    "Let's check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find feature importance of our best model\n",
    "ideal_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Helper function for plotting feature importance\n",
    "def plot_features(columns, importances, n=20):\n",
    "    df = (pd.DataFrame({\"features\": columns,\n",
    "                        \"feature_importance\": importances})\n",
    "          .sort_values(\"feature_importance\", ascending=False)\n",
    "          .reset_index(drop=True))\n",
    "    \n",
    "    sns.barplot(x=\"feature_importance\",\n",
    "                y=\"features\",\n",
    "                data=df[:n],\n",
    "                orient=\"h\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(X_train.columns, ideal_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(ideal_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ProductSize.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.ProductSize.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Turbocharged.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.Thumb.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative finish to Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function for plotting feature importance\n",
    "def plot_features(columns, importances, n=20):\n",
    "    df = (pd.DataFrame({\"features\": columns,\n",
    "                        \"feature_importances\": importances})\n",
    "          .sort_values(\"feature_importances\", ascending=False)\n",
    "          .reset_index(drop=True))\n",
    "    \n",
    "    # Plot the dataframe\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.barh(df[\"features\"][:n], df[\"feature_importances\"][:n])\n",
    "    ax.set_ylabel(\"Features\")\n",
    "    ax.set_xlabel(\"Feature importance\")\n",
    "    ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(X_train.columns, ideal_model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Enclosure\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question to finish:** Why might knowing the feature importances of a trained machine learning model be helpful?\n",
    "\n",
    "**Final challenge/extension:** What other machine learning models could you try on our dataset? Hint: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html check out the regression section of this map, or try to look at something like CatBoost.ai or XGBooost.ai."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
